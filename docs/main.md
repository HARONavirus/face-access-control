# ML System Design Doc

## Проектирование ML-системы: Система контроля доступа на основе facial recognition

### 1. Цели и предпосылки

#### 1.1. **Зачем идем в разработку продукта?**

* **Бизнес-цель:** Автоматизировать процесс идентификации личности на проходных промышленного предприятия для повышения безопасности, скорости прохода и исключения человеческого фактора. Заменить ручную проверку пропусков на автоматизированную систему распознавания лиц.

* **Почему станет лучше, чем сейчас, от использования ML?**

    * **Скорость:** Сокращение времени прохода через КПП с ~15-30 секунд (пока охранник найдет профиль и сверит фото) до ~1-3 секунд (мгновенное распознавание).

    * **Масштабируемость:** Система может обслуживать неограниченное количество проходных без увеличения штата охраны. Пиковые нагрузки (начало/конец смены) будут обрабатываться без очередей.

    * **Безопасность и объективность:** Исключение субъективности и усталости охранника. Система не может "закрыть глаза" на несоответствие или быть подвержена коррупционным схемам. Фиксируются все события прохода.

    * **Экономика:** Снижение операционных затрат в долгосрочной перспективе (меньше охранников на КПП, устранение потерь от несанкционированного доступа). Отсутствие затрат на изготовление и замену пластиковых пропусков.

* **Что будем считать успехом итерации с точки зрения бизнеса?**

    * Сокращение среднего времени прохода через КПП до < 5 секунд на человека.

    * **Точность распознавания (Recall) ≥ 99.9%** (мизийное количество "false reject" - чтобы свои сотрудники не оставлялись за дверью).

    * **Точность верификации (Precision) ≥ 99.99%** (крайне низкий уровень "false accept" - чтобы чужой не прошел).

    * Успешное развертывание и стабильная работа на 1-2 пилотных проходных в течение 1 месяца.

    * Положительные отзывы от сотрудников (отсутствие жалоб на задержки) и службы безопасности.

* [**Модель бизнес-процессов ДО разработки**](https://github.com/HARONavirus/face-access-control/blob/main/images/business_process_model_before%20.png)

* [**Модель бизнес-процессов ПОСЛЕ разработки**](https://github.com/HARONavirus/face-access-control/blob/main/images/business_process_model_after.png)

#### 1.2. Бизнес-требования и ограничения

* **Бизнес-требования:**

    * Обслуживание 5000 сотрудников и 10 проходных.

    * Время отклика системы (от захвата лица до решения) < 1 секунды.

    * Интеграция с аппаратным обеспечением: камеры, турникеты, серверы.

    * Возможность работы в условиях промышленной среды: разное освещение, погодные условия (если проходная на улице), ношение СИЗ (каски, очки).

    * Система логирования и отчетности всех событий прохода.

    * Высокий уровень кибербезопасности для защиты биометрических данных.

* **Бизнес-ограничения:**

    * **Жесткие требования к надежности:** Система не должна полностью блокировать проход в случае сбоя. Необходим механизм fallback (например, откат на проверку охранником по пропуску).

    * **Бюджет:** Ограничения на стоимость аппаратного обеспечения (камеры, вычислительные серверы) и облачной инфраструктуры (если используется).

    * **Сроки:** Разработка и внедрение пилота на 1-2 проходных — 4-6 месяцев.

    * **Нормативные требования:** Соответствие 152-ФЗ "О персональных данных" (биометрические данные — особо защищаемая категория). Требуется явное согласие сотрудников на обработку биометрии.

* [**Бизнес-процесс пилота:**](https://github.com/HARONavirus/face-access-control/blob/main/images/pilot_business_process.png)

* **Критерии успешного пилота и пути развития:**

    * **Успех:**

        * Достижение целевых метрик точности (Recall ≥ 99.9%, Precision ~100%).

        * Охранник соглашается с решением системы в > 99% случаев.

        * Стабильная работа без сбоев в течение 1 месяца.

        * Юридическая проработанность работы с биометрией.
    
    * **Развитие:**

        * Полная автоматизация (автооткрытие турникета).

        * Развертывание на всех 10 проходных.

        * Внедрение anti-spoofing (защита от масок, фотографий, 3D-моделей).

        * Интеграция с системой учета рабочего времени.
    
#### 1.3. Что входит в скоуп проекта/итерации, что не входит

* **Входит (MVP):**

    * **Модель:** Pipeline из детектора лиц (MTCNN, RetinaFace) и экстрактора признаков (FaceNet, ArcFace).

    * **Данные:** Формирование эталонной базы векторов для 5000 сотрудников.

    * **Инфраструктура:** Сервер с GPU для инференса. Камеры на проходных.

    * **Backend:** Микросервис на Python (FastAPI) для получения фото с камеры, его обработки, поиска в базе и возврата результата.

    * **Frontend:** Простой интерфейс для охранника с выводом видео, результата распознавания и фото из базы.

    * **Безопасность:** Шифрование биометрических данных на rest и in transit.

    * **Логирование:** Запись всех попыток прохода (успешных, неуспешных, сомнительных).

* **Не входит:**

    * **Anti-spoofing** (на MVP полагаемся на бдительность охранника в "советующем" режиме).

    * **Автоматическое дообучение модели** на новых данных.

    * **Распознавание в масках/шлемах** (это сложная отдельная задача).

    * **Мобильное приложение** для сотрудников.

    * **Кастомизация под разные типы турникетов** (на MVP интеграция с 1-2 типами).

* **Качество кода и воспроизводимость:**

    * Код выложен в Git

    * Использование Docker и Docker Compose для развертывания сервисов.

    * DVC для управления версиями данных и моделей.

    * Написание тестов для критичных модулей (векторизация, поиск по базе).

* **Технический долг:**

    * Реализация полноценного anti-spoofing.

    * Оптимизация скорости и потребления памяти для развертывания на edge-устройствах (Jetson) прямо на проходных.

    * Создание пайплайна для периодического переобучения модели на новых данных.

    * Разработка отказоустойчивой архитектуры (репликация базы векторов, отказ на fallback-режим).

#### 1.4. Предпосылки решения

* **Предпосылки:**

    * **Данные:** Наличие базы фотографий сотрудников (например, для пропусков) приемлемого качества (анфас, без сильных искажений, без sunglasses). Размер выборки: ~5000 изображений. *Это критичное ограничение. Если фото нет или они плохие, потребуется отдельная кампания по их сбору.*

    * **Горизонт прогноза:** Реальное время (обработка одного кадра < 1 сек).

    * **Гранулярность модели:** Распознавание одного человека в кадре (задача верификации "1:N").

* **Блоки данных:**

    * **Эталонные данные:** Фотографии сотрудников из базы данных предприятия.

    * **перативные данные:** Видеопоток с камер на проходных.

    * **Метаданные:** ID сотрудника, подразделение, допуски.

* **Обоснование:** Бизнес требует мгновенной и точной идентификации человека в условиях проходной. Современные модели глубокого обучения (например, ArcFace) показывают accuracy > 99.8% на публичных benchmark'ах и идеально подходят для задачи верификации по лицу. Задача сводится к поиску ближайшего соседа (k-NN) в пространстве векторных представлений лиц, что может быть эффективно реализовано.

### 2. Методология

#### 2.1. Постановка задачи

**Тип задачи:** Верификация лица "один-ко-многим" (1:N Identification). Система получает изображение человека, определяет лицо, извлекает его цифровой отпечаток (эмбеддинг) и ищет наиболее похожий отпечаток в заранее сформированной базе эталонных отпечатков всех сотрудников.

**Подход:** Использование сверточных нейронных сетей (CNN), предобученных на задаче распознавания лиц (например, FaceNet, ArcFace, VGGFace2). Модель преобразует изображение лица в высокоразмерный вектор (эмбеддинг), в пространстве которых расстояние между векторами коррелирует с похожестью лиц.

#### 2.2. Блок-схема решения

[**Бейзлайн и MVP:**](https://github.com/HARONavirus/face-access-control/blob/main/images/baseline_and_mvp.png)

1. **Захват кадра:** Камера на проходной передает видеопоток.

2. **Обнаружение лица:** Модель (например, MTCNN или BlazeFace) находит и выравнивает все лица на кадре.

3. **Извлечение признаков (Эмбеддинг):** Предобученная модель (например, ArcFace) преобразует выровненное изображение лица в вектор фиксированной длины (например, 512 чисел).

4. **Поиск по базе:** Вычисляется векторное расстояние (например, косинусное или евклидово) между полученным вектором и всеми векторами в эталонной базе. Находится вектор с наименьшим расстоянием.

5. **Принятие решения (Верификация):**

    * Если расстояние меньше заранее определенного порога -> СОВПАДЕНИЕ.

    * Если расстояние больше порога -> НЕСОВПАДЕНИЕ.

6. **Интеграция:** Решение передается в систему управления турникетом (для автооткрытия) или на монитор охраннику (для подтверждения).

7. **Логирование:** Все события (время, ID камеры, результат, ID сотрудника (если найден)) записываются в базу данных.

#### 2.3. Этапы решения задачи

##### **Этап 1: Подготовка данных и формирование эталонной базы**

* **Техника (бейзлайн и MVP):**

    * **Извлечение фото:** Получить фотографии из базы данных пропусков.

    * **Проверка качества:** Отфильтровать фотографии низкого качества (сильные повороты головы, темные/засвеченные, в солнцезащитных очках, не анфас). *Это критически важный шаг.*

    * **Аугментация (опционально, для улучшения базы):** Для сотрудников с одной плохой фотографией можно использовать синтетическую аугментацию (коррекция яркости/контраста, небольшие повороты) для создания 2-3 вариантов.

    * **Векторизация:** Пропустить каждое отобранное эталонное фото через пайплайн (Обнаружение -> Выравнивание -> Эмбеддинг). Полученные вектора сохраняются в базе векторов (например, `Milvus`, `Qdrant`, `Chroma`) или просто в `NumPy`-массив вместе с ID сотрудника.

* **Риски:**

    * **Низкое качество исходных фото:** Решение: запустить кампанию по пересъемке сотрудников с плохими фото или использовать аугментацию.

    * **Незаконность обработки биометрии:** Решение: юрист должен подготовить все необходимые согласия на обработку персональных данных.

##### **Этап 2: Подготовка прогнозных моделей**

* **Формирование выборки:**

    * Для **бейзлайна** не требуется отдельная обучающая выборка, используется готовая предобученная модель.

    * Для **тонкой настройки (MVP+)** потребуется собрать датасет из пар "фото -> ID сотрудника" и, возможно, негативных примеров (фото людей, которых нет в базе).

* **Горизонт и гранулярность:** Реальное время (< 1 сек), обработка одного лица в кадре.

* **Целевая переменная:** Для верификации — бинарный ответ "свой/чужой". Для идентификации — `ID` сотрудника.

* **Метрики качества:**

    * **False Rejection Rate (FRR):** % случаев, когда система не узнала своего сотрудника. **Цель: ≤ 0.1%.**

    * **False Acceptance Rate (FAR):** % случаев, когда система приняла чужого человека за своего. **Цель: ≤ 0.001% (1 на 100 000).**

    * **Accuracy:** Общая точность. **Цель: > 99.9%.**

    * **Связь с бизнесом:** Низкий FRR критически важен для пользовательского опыта (сотрудники не должны злиться). Низкий FAR критически важен для безопасности.

* **Техника:**

    * **Feature engineering:** Выравнивание лиц (alignment) по landmarks — ключевой шаг для повышения точности.

    * **Алгоритм (Бейзлайн):** Предобученная модель `ArcFace` или `FaceNet` из библиотеки `insightface`.

    * **Валидация:** Тестирование на отдельном наборе данных с известными парами "свой/чужой" для построения **кривой ROC** и точного подбора порога верификации, балансирующего FRR и FAR.

* **Результат этапа:**

    * Выбранная и протестированная модель.

    * Подобранный оптимальный порог верификации.

    * Готовая к работе эталонная база векторов.

* **Риски:**

    * **Смещение данных (Bias):** Модель, обученная на публичных данных, может хуже работать на демографических группах. Решение: проверить метрики (FAR/FRR) отдельно для разных групп и при необходимости дообучить модель.

##### **Этап 3: Интеграция бизнес-правил**

* **Техника:**

    * Определение порога уверенности (максимального косинусного расстояния) для принятия решения "Свой".

    * Реализация механизма **fallback**: если система не уверена (расстояние near the threshold) или не нашла лицо, сигнал передается охраннику для ручной проверки.

    * Настройка **антиспуфинга (на последующих итерациях)**: правило, что если модель антиспуфинга предсказывает, что это не живое лицо, доступ блокируется независимо от результата распознавания.

* **Результат этапа:** Настроенные бизнес-логика и пороги, интегрированные в основной пайплайн.

##### **Этап 4: Подготовка инференса**

* **Техника:**

    * **Архитектура:** Микросервис на `FastAPI` или `NVIDIA Triton`, который принимает изображение с камеры и возвращает `ID` сотрудника или unknown.

    * **Развертывание:**

        * **Вариант А (Централизованный):** Мощный сервер с GPU в дата-центре предприятия. Камеры стримят видео на этот сервер.

        * **Вариант Б (Edge-вычисления):** Мини-компьютер с GPU (например, NVIDIA Jetson) устанавливается прямо на каждой проходной для минимизации задержек.

    * **База векторов:** Использование оптимизированных векторных баз данных (`Milvus`, `Qdrant`) для быстрого поиска среди 5000 векторов.

* **Результат этапа:** Развернутая, протестированная под нагрузкой и отказоустойчивая система инференса.

* **Риски:**

    * **Высокая задержка (latency):** Решение: оптимизация пайплайна (например, асинхронная обработка), использование более легких моделей детекции (BlazeFace), аппаратное ускорение (GPU).

    * **Отказ камеры/сервера:** Решение: механизм health-check и автоматический переход на режим ручной проверки охранником (fallback).

### 3. Подготовка пилота

#### 3.1. Способ оценки пилота

Пилотная эксплуатация будет проводиться на 1-2 выбранных проходных предприятия. Оценка будет комплексной и включать в себя:

* **Сравнение с эталоном (Золотым стандартом):**

    * **Процесс:** Во время пилота система работает в "советующем режиме". Она показывает охраннику на монитор результат распознавания (например, "Иванов И.И., отдел №5" или "Не опознан"), **но не открывает турникет автоматически**.

    * Охранник получает пропуск сотрудника, визуально сверяет личность и принимает окончательное решение (открыть/не открыть).

    * Решение охранника считается **верным (эталонным)**.

    * Действие системы (ее "совет") логируется и сравнивается с решением охранника.

* **Сбор количественных метрик:**

    * На основе логирования автоматически рассчитываются ключевые метрики качества модели: **False Acceptance Rate (FAR)**, **False Rejection Rate (FRR)**, **Accuracy**.

    * Измеряется среднее время отклика системы (от момента захвата кадра до вывода результата на экран).

* **Сбор качественных отзывов:**

    * Проводятся опросы и интервью с **охранниками**, работавшими с системой, на предмет удобства интерфейса, скорости работы и доверия к "советам" системы.

    * Собирается обратная связь от **сотрудников** предприятия, проходящих через пилотные проходные, на предмет удобства и скорости прохода.

    * Опрашиваются **руководители службы безопасности** об удовлетворенности получаемой статистикой и отчетностью.

#### 3.2. Что считаем успешным пилотом

Пилот будет считаться успешно пройденным, если в течение 1 месяца непрерывной работы будут достигнуты следующие цели:

* **Точность и безопасность:**

    * **False Acceptance Rate (FAR) = 0%**. Ни одного случая, когда система предложила пропустить неавторизованного человека, а охранник с этим согласился. (Это критический параметр безопасности).

    * **False Rejection Rate (FRR) < 1%**. Менее 1% случаев, когда система не узнала своего сотрудника. Высокий FRR вызовет недовольство сотрудников.

    * **Согласие с системой:** Охранник соглашается с предложением системы (т.е. решение системы было верным) **более чем в 99% случаев**.

* **Производительность:**

    * **Время отклика системы:** Перцентиль 95 (P95) < 1 секунды. 95% всех запросов обрабатываются быстрее 1 секунды.

* **Надежность и стабильность:**

    * **Аптайм системы > 99.9%**. Система не должна иметь продолжительных простоев, мешающих работе проходной.

    * Отсутствие критических инцидентов, приведших к полному блокированию прохода.

* **Удовлетворенность пользователей:**

    * **Удовлетворенность охранников ≥ 80%** (по результатам анонимного опроса). Система должна восприниматься как помощник, а не помеха.

    * **Отсутствие массовых жалоб** от сотрудников на задержки при проходе.

#### 3.3. Подготовка пилота

* **Вычислительная сложность и инфраструктура:**

    * **Бейзлайн (тестовый стенд):** Развертывание пайплайна на рабочей станции с GPU потребительского уровня (NVIDIA RTX 3080/4090) для отладки и первоначального тестирования скорости.

    * **Пилот (промышленная эксплуатация):** Для каждой пилотной проходной развертывается Edge-устройство (NVIDIA Jetson Orin NX/XR) или промышленный ПК с GPU (NVIDIA A2/T4). Это обеспечит низкую задержку и независимость от сетевых проблем.

    * **Центральный сервер:** Отдельный сервер для хранения эталонной базы векторов, сбора логов и метрик со всех пилотных проходных.

* **Ограничения и планирование:**

    * **Нагрузка:** Расчет пиковой нагрузки — утренний час пик (допустим, 500 человек за 30 минут). Система должна выдерживать поток в ~16-17 человек в минуту (~1 чел/3.5 сек) на одной проходной.

    * **Ограничение по latency:** **< 1000 мс (1 секунда)** на весь цикл (захват кадра -> вывод результата). Желательная цель — **500-700 мс**.

    * **Сетевые ограничения:** При использовании центрального сервера необходимо обеспечить стабильный канал связи между камерой на проходной и сервером с низкой задержкой (Ping < 20-30 мс). **Предпочтительна edge-архитектура**.

    * **Энергопотребление и условия среды:** Оборудование на проходной должно быть устойчиво к перепадам температур, пыли и работать 24/7.

* **План развертывания:**

    1. Установка и настройка оборудования на пилотных проходных.

    2. Наполнение эталонной базы векторами сотрудников, которые чаще всего проходят через эти проходные.

    3. Включение "советующего режима" и инструктаж охранников.

    4. Запуск двухнедельного периода сбора метрик и отладки.

    5. Еще двухнедельный период финального замера метрик для принятия решения об успехе пилота.

### 4. Внедрение

#### 4.1. Архитектура решения

Система строится по гибридной edge-архитектуре для обеспечения максимальной скорости отклика и отказоустойчивости.

* [**Блок-схема решения:**]()

    * **Периферия (Edge):**

        * NVIDIA Jetson выполняет всю тяжелую обработку в реальном времени: детекция, распознавание, принятие решения.

        * Использует локальную базу векторов для максимальной скорости работы и независимости от качества сети.

        * Отправляет только результаты и логи на центральный сервер.

    * **Взаимодействие с физическим миром:**

        * Решение с Edge-устройства сразу управляет турникетом (автоматический режим).

        * Одновременно дублируется на интерфейс охранника для ручного подтверждения или работы в "советующем" режиме.

    * **Центральный сервер:**

        * Выполняет функции управления, аналитики и долгосрочного хранения.

        * Хранилище векторов синхронизируется с локальными базами на всех Edge-устройствах.

        * Дашборд предоставляет инструмент для контроля и анализа всей системы безопасности.

* **Методы API Центрального сервера:**

    * `POST /api/v1/event` - Отправка события прохода с edge-устройства (ID камеры, timestamp, ID сотрудника, результат, фото).

    * `GET /api/v1/employees` - Получение списка сотрудников и их эталонных данных для синхронизации edge-устройства.

    * `POST /api/v1/admin/override` - API для ручного открытия турникета из центральной диспетчерской.

* [**ER-диаграмма (ключевые сущности):**]()

#### 4.2. Описание инфраструктуры и масштабируемости

* **Инфраструктура:** Гибридная (**On-Premise** + **Cloud**).

    * **Edge-слой**: Устройства **NVIDIA Jetson Orin** на каждой проходной. Обрабатывают видео в реальном времени, автономны.

    * **Центральный слой:** Локальный сервер на предприятии или облачный инстанс (**Yandex Cloud** / **Selectel**). Выбор обусловлен требованиями 152-ФЗ к локализации персональных (и особенно биометрических) данных.

* **Почему выбрана:**

    * **Задержка (Latency):** Edge-устройства исключают сетевую задержку для критичного пути распознавания.

    * **Отказоустойчивость:** Проходные продолжают работать даже при потере связи с центром (требуется периодическая синхронизация базы векторов).

    * **Конфиденциальность:** Биометрические данные (векторы) обрабатываются локально, на edge, и не передаются по сети в центральную базу. Передается только результат (ID сотрудника).

* **Плюсы:**

    * Высокая скорость и надежность.

    * Соответствие требованиям регуляторов.

    * Легкое масштабирование: добавление новой проходной = установка нового edge-устройства.

* **Минусы:**

    * Более высокая первоначальная стоимость аппаратного обеспечения на каждую проходную.

    * Усложнение процесса обновления ПО на распределенных устройствах.

#### 4.3. Требования к работе системы

* **SLA**: 99.9% доступности для центрального сервера. 99.99% для edge-устройств (так как их отказ напрямую останавливает работу проходной).

* **RPS**: На edge-устройстве расчет ведется не в RPS, а в **FPS (кадры в секунду)**. Требование: обработка **≥ 10 FPS** для уверенного захвата лица идущего человека.

* **Latency**: **P95 < 700 мс** на edge-устройстве (от захвата кадра до решения).

#### 4.4. Безопасность системы

* **Уязвимости:**

    * **Атаки на оборудование:** Физический доступ к edge-устройству или камере.

    * **Атаки на сеть:** Перехват данных между edge и центром.

    * **Спуфинг-атаки:** Попытка обмана системы с помощью маски, фото или видео на экране.

* **Решение:**

    * **Физическая безопасность:** Размещение edge-устройств в защищенных боксах.

    * **Сетевая безопасность:** VPN-туннели между edge-устройствами и центральным сервером. Защита API Gateway с помощью WAF (Web Application Firewall).

    * **Антиспуфинг:** На последующих итерациях внедрить отдельную нейросеть (Liveness Detection), определяющую, живое ли перед камерой лицо.

#### 4.5. Безопасность данных

* **Конфиденциальность**: Эталонные эмбеддинги хранятся в зашифрованном виде. JPEG-фотографии, используемые для логирования событий, хранятся в зашифрованном виде и строго ограничены по времени хранения (например, 30 дней).

* **Соответствие**: Полное соответствие 152-ФЗ "О персональных данных" и ФЗ-xxx "О биометрических данных". Все сотрудники предоставляют явное письменное согласие на обработку биометрических данных.

* **Анонимизация**: В отчетах и дашбордах для аналитиков данные обезличены (используются ID, а не ФИО).

#### 4.6. Издержки (CAPEX + OPEX)

* **Единовременные затраты (CAPEX):**

    * Edge-устройство (NVIDIA Jetson Orin) на 1 проходную: ~$2 000.

    * Промышленная камера высокого разрешения: ~$500.

    * **Итого на 10 проходных: ~$25 000.**

* **Операционные затраты (OPEX) в месяц:**

    * Облачный инстанс для центрального сервера (8 vCPU, 32 GB RAM, GPU): ~$500/мес.

    * Облачное хранилище и база данных: ~$200/мес.

    * Техническое обслуживание и поддержка: ~$1000/мес.

    * **Итого: ~$1 700/мес.**

#### 4.7. Integration points

* **Edge** -> **Центр**:` REST API /api/v1/event` для отправки событий. `REST API /api/v1/employees` для синхронизации списка сотрудников.

* **Центр** -> **СУБД**: `SQL` для записи событий и конфигурации.

* **Центр** -> **Дашборд**: `WebSocket` или `REST API` для отдачи данных в реальном времени.

* **Edge** -> **Контроллер турникета: Сухой контакт (GPIO)** или `RS-485` — наиболее надежный и безопасный способ интеграции с аппаратным обеспечением проходной.

#### 4.8. Риски

* **Сбой на edge-устройстве:**

    * **Решение**: Наличие встроенного механизма **fallback**. При обнаружении сбоя устройство посылает сигнал на переключение проходной в режим ручной проверки охранником.

* **"Затухание"** модели (Model Drift):

    * **Решение**: Регулярный (ежегодный) сбор новых эталонных фото сотрудников (например, при перевыпуске пропусков) и периодическое перестроение эталонной базы векторов.

* **Юридические риски:**

    * **Решение**: Постоянный юридический мониторинг и работа с регуляторами. Четкие регламенты хранения и удаления биометрических данных.

* **Низкое качество видеопотока:**

    * **Решение**: Регулярная проверка и очистка камер, настройка позиционирования и освещения на проходной.
