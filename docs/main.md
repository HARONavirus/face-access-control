# ML System Design Doc

## Проектирование ML-системы: Система контроля доступа на основе facial recognition

### 1. Цели и предпосылки

#### 1.1. **Зачем идем в разработку продукта?**

* **Бизнес-цель:** Автоматизировать процесс идентификации личности на проходных промышленного предприятия для повышения безопасности, скорости прохода и исключения человеческого фактора. Заменить ручную проверку пропусков на автоматизированную систему распознавания лиц.

* **Почему станет лучше, чем сейчас, от использования ML?**

    * **Скорость:** Сокращение времени прохода через КПП с ~15-30 секунд (пока охранник найдет профиль и сверит фото) до ~1-3 секунд (мгновенное распознавание).

    * **Масштабируемость:** Система может обслуживать неограниченное количество проходных без увеличения штата охраны. Пиковые нагрузки (начало/конец смены) будут обрабатываться без очередей.

    * **Безопасность и объективность:** Исключение субъективности и усталости охранника. Система не может "закрыть глаза" на несоответствие или быть подвержена коррупционным схемам. Фиксируются все события прохода.

    * **Экономика:** Снижение операционных затрат в долгосрочной перспективе (меньше охранников на КПП, устранение потерь от несанкционированного доступа). Отсутствие затрат на изготовление и замену пластиковых пропусков.

* **Что будем считать успехом итерации с точки зрения бизнеса?**

    * Сокращение среднего времени прохода через КПП до < 5 секунд на человека.

    * **Точность распознавания (Recall) ≥ 99.9%** (мизийное количество "false reject" - чтобы свои сотрудники не оставлялись за дверью).

    * **Точность верификации (Precision) ≥ 99.99%** (крайне низкий уровень "false accept" - чтобы чужой не прошел).

    * Успешное развертывание и стабильная работа на 1-2 пилотных проходных в течение 1 месяца.

    * Положительные отзывы от сотрудников (отсутствие жалоб на задержки) и службы безопасности.

* [**Модель бизнес-процессов ДО разработки**]()

* [**Модель бизнес-процессов ПОСЛЕ разработки**]()

#### 1.2. Бизнес-требования и ограничения

* **Бизнес-требования:**

    * Обслуживание 5000 сотрудников и 10 проходных.

    * Время отклика системы (от захвата лица до решения) < 1 секунды.

    * Интеграция с аппаратным обеспечением: камеры, турникеты, серверы.

    * Возможность работы в условиях промышленной среды: разное освещение, погодные условия (если проходная на улице), ношение СИЗ (каски, очки).

    * Система логирования и отчетности всех событий прохода.

    * Высокий уровень кибербезопасности для защиты биометрических данных.

* **Бизнес-ограничения:**

    * **Жесткие требования к надежности:** Система не должна полностью блокировать проход в случае сбоя. Необходим механизм fallback (например, откат на проверку охранником по пропуску).

    * **Бюджет:** Ограничения на стоимость аппаратного обеспечения (камеры, вычислительные серверы) и облачной инфраструктуры (если используется).

    * **Сроки:** Разработка и внедрение пилота на 1-2 проходных — 4-6 месяцев.

    * **Нормативные требования:** Соответствие 152-ФЗ "О персональных данных" (биометрические данные — особо защищаемая категория). Требуется явное согласие сотрудников на обработку биометрии.

* [**Бизнес-процесс пилота:**]()

* **Критерии успешного пилота и пути развития:**

    * **Успех:**

        * Достижение целевых метрик точности (Recall ≥ 99.9%, Precision ~100%).

        * Охранник соглашается с решением системы в > 99% случаев.

        * Стабильная работа без сбоев в течение 1 месяца.

        * Юридическая проработанность работы с биометрией.
    
    * **Развитие:**

        * Полная автоматизация (автооткрытие турникета).

        * Развертывание на всех 10 проходных.

        * Внедрение anti-spoofing (защита от масок, фотографий, 3D-моделей).

        * Интеграция с системой учета рабочего времени.
    
#### 1.3. Что входит в скоуп проекта/итерации, что не входит

* **Входит (MVP):**

    * **Модель:** Pipeline из детектора лиц (MTCNN, RetinaFace) и экстрактора признаков (FaceNet, ArcFace).

    * **Данные:** Формирование эталонной базы векторов для 5000 сотрудников.

    * **Инфраструктура:** Сервер с GPU для инференса. Камеры на проходных.

    * **Backend:** Микросервис на Python (FastAPI) для получения фото с камеры, его обработки, поиска в базе и возврата результата.

    * **Frontend:** Простой интерфейс для охранника с выводом видео, результата распознавания и фото из базы.

    * **Безопасность:** Шифрование биометрических данных на rest и in transit.

    * **Логирование:** Запись всех попыток прохода (успешных, неуспешных, сомнительных).

* **Не входит:**

    * **Anti-spoofing** (на MVP полагаемся на бдительность охранника в "советующем" режиме).

    * **Автоматическое дообучение модели** на новых данных.

    * **Распознавание в масках/шлемах** (это сложная отдельная задача).

    * **Мобильное приложение** для сотрудников.

    * **Кастомизация под разные типы турникетов** (на MVP интеграция с 1-2 типами).

* **Качество кода и воспроизводимость:**

    * Код выложен в Git

    * Использование Docker и Docker Compose для развертывания сервисов.

    * DVC для управления версиями данных и моделей.

    * Написание тестов для критичных модулей (векторизация, поиск по базе).

* **Технический долг:**

    * Реализация полноценного anti-spoofing.

    * Оптимизация скорости и потребления памяти для развертывания на edge-устройствах (Jetson) прямо на проходных.

    * Создание пайплайна для периодического переобучения модели на новых данных.

    * Разработка отказоустойчивой архитектуры (репликация базы векторов, отказ на fallback-режим).

#### 1.4. Предпосылки решения

* **Предпосылки:**

    * **Данные:** Наличие базы фотографий сотрудников (например, для пропусков) приемлемого качества (анфас, без сильных искажений, без sunglasses). Размер выборки: ~5000 изображений. *Это критичное ограничение. Если фото нет или они плохие, потребуется отдельная кампания по их сбору.*

    * **Горизонт прогноза:** Реальное время (обработка одного кадра < 1 сек).

    * **Гранулярность модели:** Распознавание одного человека в кадре (задача верификации "1:N").

* **Блоки данных:**

    * **Эталонные данные:** Фотографии сотрудников из базы данных предприятия.

    * **перативные данные:** Видеопоток с камер на проходных.

    * **Метаданные:** ID сотрудника, подразделение, допуски.

* **Обоснование:** Бизнес требует мгновенной и точной идентификации человека в условиях проходной. Современные модели глубокого обучения (например, ArcFace) показывают accuracy > 99.8% на публичных benchmark'ах и идеально подходят для задачи верификации по лицу. Задача сводится к поиску ближайшего соседа (k-NN) в пространстве векторных представлений лиц, что может быть эффективно реализовано.

### 2. Методология

#### 2.1. Постановка задачи

**Тип задачи:** Верификация лица "один-ко-многим" (1:N Identification). Система получает изображение человека, определяет лицо, извлекает его цифровой отпечаток (эмбеддинг) и ищет наиболее похожий отпечаток в заранее сформированной базе эталонных отпечатков всех сотрудников.

**Подход:** Использование сверточных нейронных сетей (CNN), предобученных на задаче распознавания лиц (например, FaceNet, ArcFace, VGGFace2). Модель преобразует изображение лица в высокоразмерный вектор (эмбеддинг), в пространстве которых расстояние между векторами коррелирует с похожестью лиц.

#### 2.2. Блок-схема решения

[**Бейзлайн и MVP:**]()

1. **Захват кадра:** Камера на проходной передает видеопоток.

2. **Обнаружение лица:** Модель (например, MTCNN или BlazeFace) находит и выравнивает все лица на кадре.

3. **Извлечение признаков (Эмбеддинг):** Предобученная модель (например, ArcFace) преобразует выровненное изображение лица в вектор фиксированной длины (например, 512 чисел).

4. **Поиск по базе:** Вычисляется векторное расстояние (например, косинусное или евклидово) между полученным вектором и всеми векторами в эталонной базе. Находится вектор с наименьшим расстоянием.

5. **Принятие решения (Верификация):**

    * Если расстояние меньше заранее определенного порога -> СОВПАДЕНИЕ.

    * Если расстояние больше порога -> НЕСОВПАДЕНИЕ.

6. **Интеграция:** Решение передается в систему управления турникетом (для автооткрытия) или на монитор охраннику (для подтверждения).

7. **Логирование:** Все события (время, ID камеры, результат, ID сотрудника (если найден)) записываются в базу данных.

#### 2.3. Этапы решения задачи

##### **Этап 1: Подготовка данных и формирование эталонной базы**

* **Техника (бейзлайн и MVP):**

    * **Извлечение фото:** Получить фотографии из базы данных пропусков.

    * **Проверка качества:** Отфильтровать фотографии низкого качества (сильные повороты головы, темные/засвеченные, в солнцезащитных очках, не анфас). *Это критически важный шаг.*

    * **Аугментация (опционально, для улучшения базы):** Для сотрудников с одной плохой фотографией можно использовать синтетическую аугментацию (коррекция яркости/контраста, небольшие повороты) для создания 2-3 вариантов.

    * **Векторизация:** Пропустить каждое отобранное эталонное фото через пайплайн (Обнаружение -> Выравнивание -> Эмбеддинг). Полученные вектора сохраняются в базе векторов (например, `Milvus`, `Qdrant`, `Chroma`) или просто в `NumPy`-массив вместе с ID сотрудника.

* **Риски:**

    * **Низкое качество исходных фото:** Решение: запустить кампанию по пересъемке сотрудников с плохими фото или использовать аугментацию.

    * **Незаконность обработки биометрии:** Решение: юрист должен подготовить все необходимые согласия на обработку персональных данных.

##### **Этап 2: Подготовка прогнозных моделей**

* **Формирование выборки:**

    * Для **бейзлайна** не требуется отдельная обучающая выборка, используется готовая предобученная модель.

    * Для **тонкой настройки (MVP+)** потребуется собрать датасет из пар "фото -> ID сотрудника" и, возможно, негативных примеров (фото людей, которых нет в базе).

* **Горизонт и гранулярность:** Реальное время (< 1 сек), обработка одного лица в кадре.

* **Целевая переменная:** Для верификации — бинарный ответ "свой/чужой". Для идентификации — `ID` сотрудника.

* **Метрики качества:**

    * **False Rejection Rate (FRR):** % случаев, когда система не узнала своего сотрудника. **Цель: ≤ 0.1%.**

    * **False Acceptance Rate (FAR):** % случаев, когда система приняла чужого человека за своего. **Цель: ≤ 0.001% (1 на 100 000).**

    * **Accuracy:** Общая точность. **Цель: > 99.9%.**

    * **Связь с бизнесом:** Низкий FRR критически важен для пользовательского опыта (сотрудники не должны злиться). Низкий FAR критически важен для безопасности.

* **Техника:**

    * **Feature engineering:** Выравнивание лиц (alignment) по landmarks — ключевой шаг для повышения точности.

    * **Алгоритм (Бейзлайн):** Предобученная модель `ArcFace` или `FaceNet` из библиотеки `insightface`.

    * **Валидация:** Тестирование на отдельном наборе данных с известными парами "свой/чужой" для построения **кривой ROC** и точного подбора порога верификации, балансирующего FRR и FAR.

* **Результат этапа:**

    * Выбранная и протестированная модель.

    * Подобранный оптимальный порог верификации.

    * Готовая к работе эталонная база векторов.

* **Риски:**

    * **Смещение данных (Bias):** Модель, обученная на публичных данных, может хуже работать на демографических группах. Решение: проверить метрики (FAR/FRR) отдельно для разных групп и при необходимости дообучить модель.

##### **Этап 3: Интеграция бизнес-правил**

* **Техника:**

    * Определение порога уверенности (максимального косинусного расстояния) для принятия решения "Свой".

    * Реализация механизма **fallback**: если система не уверена (расстояние near the threshold) или не нашла лицо, сигнал передается охраннику для ручной проверки.

    * Настройка **антиспуфинга (на последующих итерациях)**: правило, что если модель антиспуфинга предсказывает, что это не живое лицо, доступ блокируется независимо от результата распознавания.

* **Результат этапа:** Настроенные бизнес-логика и пороги, интегрированные в основной пайплайн.

##### **Этап 4: Подготовка инференса**

* **Техника:**

    * **Архитектура:** Микросервис на `FastAPI` или `NVIDIA Triton`, который принимает изображение с камеры и возвращает `ID` сотрудника или unknown.

    * **Развертывание:**

        * **Вариант А (Централизованный):** Мощный сервер с GPU в дата-центре предприятия. Камеры стримят видео на этот сервер.

        * **Вариант Б (Edge-вычисления):** Мини-компьютер с GPU (например, NVIDIA Jetson) устанавливается прямо на каждой проходной для минимизации задержек.

    * **База векторов:** Использование оптимизированных векторных баз данных (`Milvus`, `Qdrant`) для быстрого поиска среди 5000 векторов.

* **Результат этапа:** Развернутая, протестированная под нагрузкой и отказоустойчивая система инференса.

* **Риски:**

    * **Высокая задержка (latency):** Решение: оптимизация пайплайна (например, асинхронная обработка), использование более легких моделей детекции (BlazeFace), аппаратное ускорение (GPU).

    * **Отказ камеры/сервера:** Решение: механизм health-check и автоматический переход на режим ручной проверки охранником (fallback).
